{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHItyF7Dlce9",
        "outputId": "e6de21c2-41bf-4341-f3ef-95425f1beddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.4\n",
            "    Uninstalling spacy-3.5.4:\n",
            "      Successfully uninstalled spacy-3.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYNQ9ykvlwjm",
        "outputId": "64543882-d01f-4d3a-b62a-c016380354f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-20 04:24:42.623713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-20 04:24:44.066283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "matcher = Matcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "OizURutMlz9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataBase = {\n",
        "        \"tabla\": \"productos\",\n",
        "        \"columnas\": [\"id\", \"codigo\", \"cantidad\", \"descripcion\"]\n",
        "}\n",
        "\n",
        "Operator = {\n",
        "    \"!=\": [\"distinto\", \"diferente\",\"diverso\",\"desigual\",\"desemejante\"],\n",
        "    \"<\": [\"menos\", \"anterior\", \"antes\", \"menores\",\"pequeños\"],\n",
        "    \">\": [\"mayor\", \"posterior\", \"despues\", \"mayores\",\"luego\"],\n",
        "    \">=\": [\"mayor igual\", \"igual mayor\",\"igual y posterior\", \"igual y despues\", \"igual y mayores\",\"luego\"],\n",
        "    \"<=\": [\"menor igual\", \"igual menor\",\"igual y anterior\", \"igual y antes\", \"igual y menores\",\"igual y pequeños\"],\n",
        "    \"not\": [\"no\"]\n",
        "}"
      ],
      "metadata": {
        "id": "nyk9Z3tYl9Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action=  {\n",
        "        \"SELECT\": [\"dame\",\"seleccionar\", \"obtener\", \"extraer\", \"mostrar\"],\n",
        "}"
      ],
      "metadata": {
        "id": "Ko7wJeZfmBrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getWords(frase):\n",
        "    doc = nlp(frase)\n",
        "    palabras_importantes = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ in [\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\", \"ADV\", \"NUM\"] or token.ent_type_ == \"DATE\":\n",
        "            palabras_importantes.append(token.text)\n",
        "\n",
        "    palabrasImportantes = ' '.join(palabras_importantes)\n",
        "\n",
        "    return palabrasImportantes"
      ],
      "metadata": {
        "id": "Uzwn8oxJmPJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAction(frase_ingresada, matcher, action):\n",
        "  doc = nlp(frase_ingresada.lower())\n",
        "  for accion, palabras in action.items():\n",
        "      patterns = [[{\"LOWER\": palabra}] for palabra in palabras]\n",
        "      matcher.add(accion, patterns)\n",
        "\n",
        "  matches = matcher(doc)\n",
        "\n",
        "  for match_id, start, end in matches:\n",
        "      accion = nlp.vocab.strings[match_id]\n",
        "      frase_ingresada = \" \".join([token.text for token in doc if token.i < start or token.i >= end])\n",
        "\n",
        "      return accion, frase_ingresada.strip()\n",
        "  return None,frase_ingresada"
      ],
      "metadata": {
        "id": "O89Gm8ztmRg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSimilarity(frase, DataBase):\n",
        "    doc = nlp(frase)\n",
        "    tablasNew = set()\n",
        "    columnasNew = set()\n",
        "\n",
        "    for token_frase in doc:\n",
        "        similitud_tabla = token_frase.similarity(nlp(DataBase[\"tabla\"]))\n",
        "        if similitud_tabla >= 0.6:\n",
        "            tablasNew.add(DataBase[\"tabla\"])\n",
        "        for token_frase in doc:\n",
        "            for columna in DataBase[\"columnas\"]:\n",
        "                similitud = token_frase.similarity(nlp(columna))\n",
        "                if similitud > 0.6 and columna in token_frase.text:\n",
        "                    columnasNew.add(columna)\n",
        "    return tablasNew, columnasNew"
      ],
      "metadata": {
        "id": "x7QPRiK_mWHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getOperator(frase, matcher, Operator):\n",
        "    doc = nlp(frase.lower())\n",
        "\n",
        "    for operador, palabras in Operator.items():\n",
        "        patterns = [[{\"LOWER\": palabra}] for palabra in palabras]\n",
        "        matcher.add(operador.lower(), patterns)\n",
        "\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        operador = nlp.vocab.strings[match_id]\n",
        "        frase = \" \".join([token.text for token in doc if token.i < start or token.i >= end])\n",
        "\n",
        "        return operador, frase.strip()\n",
        "\n",
        "    return None, frase"
      ],
      "metadata": {
        "id": "FMxwEzA9mYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extraWords(frase, matcher, DataBase,action,Operator):\n",
        "    p_importantes = getWords(frase)\n",
        "    accion, fraseDevuelta = getAction(p_importantes, matcher, action)\n",
        "    resultados_tabla, resultados_columnas = getSimilarity(frase, DataBase)\n",
        "\n",
        "    p_restantes = set(fraseDevuelta.split()) - resultados_tabla - resultados_columnas\n",
        "    p_res = ' '.join(p_restantes)\n",
        "\n",
        "    operador, frase_2 = getOperator(p_res, matcher, Operator)\n",
        "\n",
        "    condicion = \"\"\n",
        "    if operador and frase_2:\n",
        "        doc = nlp(frase_2)\n",
        "        for token in doc:\n",
        "            if token.pos_ in [ \"PROPN\",\"NUM\"] or token.ent_type_ == \"DATE\":\n",
        "                condicion += token.text + \" \"\n",
        "            elif token.pos_ in [\"VERB\", \"ADJ\"]:\n",
        "                condicion += token.lemma_ + \" \"\n",
        "\n",
        "    return accion, resultados_tabla, resultados_columnas, operador,frase_2, condicion.strip()"
      ],
      "metadata": {
        "id": "FenBmYPdmaSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consultSql(accion, tablas, columnas, operador, condicion):\n",
        "    consulta = \"\"\n",
        "    condiciones = []\n",
        "    if columnas:\n",
        "      colum_sql_list = list(columnas)\n",
        "      if operador:\n",
        "        operaciones_list = list(operador)\n",
        "        condiciones = f\"{colum_sql_list[0]} {operaciones_list[0]} {condicion}\"\n",
        "    if accion == \"SELECT\":\n",
        "        if columnas:\n",
        "            consulta += f\"SELECT {', '.join(columnas)} FROM {', '.join(tablas)}\"\n",
        "        else:\n",
        "            consulta += f\"SELECT * FROM {', '.join(tablas)}\"\n",
        "\n",
        "        if condiciones:\n",
        "            consulta += f\" WHERE {condiciones}\"\n",
        "    return consulta"
      ],
      "metadata": {
        "id": "WCzJuOGlmcrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"obtener fecah de nacimiento de los estudiantes\"\n",
        "\n",
        "accion,tableSql, columnSql, operator, rest, condition = extraWords(sentence, matcher, DataBase,action, Operator)\n",
        "sqlQuery = consultSql(accion,tableSql, columnSql, operator, condition)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dN5-9gCme4X",
        "outputId": "466ecd1a-4f65-4939-f87e-d31cc7a97b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b52548da82f2>:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similitud_tabla = token_frase.similarity(nlp(DataBase[\"tabla\"]))\n",
            "<ipython-input-9-b52548da82f2>:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similitud = token_frase.similarity(nlp(columna))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eh05_kR76gfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SQL Query:\",sqlQuery)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZBPsUrvm01k",
        "outputId": "c8fbad99-26cf-42e8-ecf0-e6c16efe3ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQL Query: SELECT * FROM \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CsIHGEC56biu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}